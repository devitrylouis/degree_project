load.libraries <- c('data.table', 'testthat', 'gridExtra', 'corrplot', 'GGally', 'ggplot2', 'e1071', 'dplyr','leaps','car','MASS','gtools','DAAG','glmnet')
install.lib <- load.libraries[!load.libraries %in% installed.packages()]
for(libs in install.lib) install.packages(libs, dependences = TRUE)
sapply(load.libraries, require, character = TRUE)
# include DAAG
# Function sources
source('~/Desktop/factoring.R')
source('~/Desktop/analysis.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Descriptive and Comparative Analysis/analysis.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/fitting.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Transformations/transformed_fitting.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/quadratic.R')
source('~/Desktop/quadratic_transform.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/remove_neighborhood.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Descriptive and Comparative Analysis/plot_comparison.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Shrinkage Methods/ridge_regression.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Shrinkage Methods/lasso.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Higher Terms/quadratic_predictors.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/cubic.R')
# Importation of training and test set
train <- fread("/Users/louisdevitry/Documents/Education/KTH/Bachelor thesis/Data/train.csv" ,stringsAsFactors=FALSE)
test <- fread("/Users/louisdevitry/Documents/Education/KTH/Bachelor thesis/Data/test.csv" ,stringsAsFactors=FALSE)
# Choose neighborhoods of interest
neigh<-FALSE
if(neigh){train<-removing_neighborhoods(train)}
# Linear Model
# Multiple Linear Model
model<-fitting(train)
output<-analysis(df,model,residuals=TRUE,boxcox=TRUE,multicollinearity=TRUE,outliers=TRUE)
# Transformed Multiple Linear Model
model_transformed <- transformed(model,output,df,1)
output_transformed<-analysis(df1,model_transformed,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=TRUE)
df2<-quadratic_predictors(df1,4)
# Necessaries libraries to explore the data
load.libraries <- c('data.table', 'testthat', 'gridExtra', 'corrplot', 'GGally', 'ggplot2', 'e1071', 'dplyr','leaps','car','MASS','gtools','DAAG','glmnet')
install.lib <- load.libraries[!load.libraries %in% installed.packages()]
for(libs in install.lib) install.packages(libs, dependences = TRUE)
sapply(load.libraries, require, character = TRUE)
# include DAAG
# Function sources
source('~/Desktop/factoring.R')
source('~/Desktop/analysis.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Descriptive and Comparative Analysis/analysis.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/fitting.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Transformations/transformed_fitting.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/quadratic.R')
source('~/Desktop/quadratic_transform.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/remove_neighborhood.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Descriptive and Comparative Analysis/plot_comparison.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Shrinkage Methods/ridge_regression.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Shrinkage Methods/lasso.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Higher Terms/quadratic_predictors.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/cubic.R')
# Importation of training and test set
train <- fread("/Users/louisdevitry/Documents/Education/KTH/Bachelor thesis/Data/train.csv" ,stringsAsFactors=FALSE)
test <- fread("/Users/louisdevitry/Documents/Education/KTH/Bachelor thesis/Data/test.csv" ,stringsAsFactors=FALSE)
# Choose neighborhoods of interest
neigh<-FALSE
if(neigh){train<-removing_neighborhoods(train)}
# Linear Model
# Multiple Linear Model
model<-fitting(train)
output<-analysis(df,model,residuals=TRUE,boxcox=TRUE,multicollinearity=TRUE,outliers=TRUE)
# Transformed Multiple Linear Model
model_transformed <- transformed(model,output,df,1)
output_transformed<-analysis(df1,model_transformed,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=TRUE)
# Multiple Linear Model with higher terms of interest
df2<-quadratic_predictors(df1,4)
model_squared <- transformed(model_transformed,output_transformed,df2,3)
output_squared <- analysis(df3,model_squared,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=TRUE)
# Transformed Multiple Linear Model with higher terms
model_squared_transformed <- transformed(model_squared,output_squared,df3,4)
output<-analysis(df4,model_squared_transformed,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=FALSE)
# Lasso
lasso <- lasso_model(df3)
# Ridge Regression
ridge <- ridge_regression_model(df3)
# Plot of the models assessment
plot_comparison()
View(df4)
# Fix some NAs
test$GarageYrBlt[is.na(test$GarageYrBlt)] <- mean(train$GarageYrBlt[!is.na(train$GarageYrBlt)])
test$MasVnrArea[is.na(test$MasVnrArea)] <- mean(train$MasVnrArea[!is.na(train$MasVnrArea)])
test$LotFrontage[is.na(test$LotFrontage)] <- mean(train$LotFrontage[!is.na(train$LotFrontage)])
# Factoring categorical predictors
new_names <<- c('paved','regshape','alley_pave','flat','gentle_slope','cul_de_sac_fr3'
,'nbhd_price_level','prox1','prox2','dwelling','house_style_price_level','roof_style'
,'roof_matl','ext1_price_level','ext2_price_level','masonry_type'
,'exterior_qual_level','exterior_cond_level','foundation_level'
,'basement_qual_level','basement_cond_level','basement_exposure_level'
,'basementfin_type1_level','basementfin_type2_level','heating_level'
,'heating_qc_level','central_air_yes','electrical_level','kitchen_qual_level'
,'functionality_level','fireplace_qual_level','garage_type_level'
,'garage_finish_level','garage_qual_level','garage_cond_level'
,'paved_driveway_level','pool_qc_level','fence_qual_level','sale_type_level'
,'sale_condition_level','zoning_level')
# Original names of the categorical predictors
old_names <<- c('Street','LotShape','Alley','LandContour','LandSlope','LotConfig'
,'Neighborhood','Condition1','Condition2','BldgType','HouseStyle'
,'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType'
,'ExterQual','ExterCond','Foundation','BsmtQual','BsmtCond'
,'BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC'
,'CentralAir','Electrical','KitchenQual','Functional','FireplaceQu'
,'GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive'
,'PoolQC','Fence','SaleType','SaleCondition','MSZoning')
# Future list of the mean price per level for each predictor
price_summary <- list()
# Factoring the data accoding to the aforementioned list
for (i in 1:length(old_names))
{
# Construction of the list
price_summary[[i]]<-summarize(group_by(train, train[[old_names[i]]]),mean(SalePrice, na.rm=T))
matrix<-as.matrix(price_summary[[i]])
# Handling NA levels
# Temporary variable to control NA values
temp<-0
# Factor NA level if any
if(is.na(matrix[dim(matrix)[1],1]))
{
temp<-1
test[[new_names[i]]][is.na(test[[old_names[i]]])]<-matrix[dim(matrix)[1],2]
}
# Factor non NA levels
for (j in 1:(dim(matrix)[1]-temp))
{
test[[new_names[i]]][test[[old_names[i]]]==matrix[j,1]]<-matrix[j,2]
}
# Convert factors into numeric ones
test[[new_names[i]]]<-as.numeric(test[[new_names[i]]])
}
# Deleting factored/unwanted predictors
test$Id <- NULL
test$GrLivArea <- NULL
test$TotalBsmtSF <- NULL
test$Utilities<-NULL
test$MiscFeature <- NULL
test$MiscVal <- NULL
assign("seqq",which(colnames(test) %in% old_names))
# Linear model preparation
# Removing duplicate/unwanted columns
df_test <- test
df_test <- subset(df_test, select = -seqq )
df_test[["1stFlrSF 2"]] <- df_test[["1stFlrSF"]]^2
df_test[["OpenPorchSF 4"]] <- df_test[["OpenPorchSF"]]^4
df_test[["GarageYrBlt 4"]] <- df_test[["GarageYrBlt"]]^4
df_test[["BsmtFullBath 3"]] <- df_test[["BsmtFullBath"]]^3
df_test[is.na(df_test)] <- 0
fit.pred <- exp(predict(model_transformed,df_test))
fit.pred.squared <- exp(predict(model_squared,df_test))
fit.pred.squared.transformed <- exp(predict(model_squared_transformed,df_test))
write.csv(data.frame(fit.pred),file = "fit_pred.csv")
write.csv(data.frame(fit.pred.squared),file = "fit_pred_squared.csv")
write.csv(data.frame(fit.pred.squared.transformed),file = "fit_pred_squared_transformed.csv")
ridge.pred<-predict(ridge[[3]],s=ridge[[2]],as.matrix(df_test))
ridge.pred<-exp(ridge.pred)
write.csv(data.frame(ridge.pred),file="ridge.csv")
lasso.pred<-predict(lasso[[3]],s=lasso[[2]],as.matrix(df_test))
lasso.pred<-exp(lasso.pred)
write.csv(data.frame(ridge.pred),file="lasso.csv")
write.csv(data.frame(lasso.pred),file="lasso.csv")
write.csv(data.frame(lasso.pred),file="lasso.csv")
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Higher Terms/quadratic_predictors.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Higher Terms/higher_terms.R')
# Necessaries libraries to explore the data
load.libraries <- c('data.table', 'testthat', 'gridExtra', 'corrplot', 'GGally', 'ggplot2', 'e1071', 'dplyr','leaps','car','MASS','gtools','DAAG','glmnet')
install.lib <- load.libraries[!load.libraries %in% installed.packages()]
for(libs in install.lib) install.packages(libs, dependences = TRUE)
sapply(load.libraries, require, character = TRUE)
# include DAAG
# Function sources
source('~/Desktop/factoring.R')
source('~/Desktop/analysis.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Descriptive and Comparative Analysis/analysis.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/fitting.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Transformations/transformed_fitting.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/quadratic.R')
source('~/Desktop/quadratic_transform.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/remove_neighborhood.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Descriptive and Comparative Analysis/plot_comparison.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Shrinkage Methods/ridge_regression.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Shrinkage Methods/lasso.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Higher Terms/higher_terms.R')
# Importation of training and test set
train <- fread("/Users/louisdevitry/Documents/Education/KTH/Bachelor thesis/Data/train.csv" ,stringsAsFactors=FALSE)
test <- fread("/Users/louisdevitry/Documents/Education/KTH/Bachelor thesis/Data/test.csv" ,stringsAsFactors=FALSE)
# Choose neighborhoods of interest
neigh<-FALSE
if(neigh){train<-removing_neighborhoods(train)}
# Linear Model
# Multiple Linear Model
model<-fitting(train)
output<-analysis(df,model,residuals=TRUE,boxcox=TRUE,multicollinearity=TRUE,outliers=TRUE)
# Transformed Multiple Linear Model
model_transformed <- transformed(model,output,df,1)
output_transformed<-analysis(df1,model_transformed,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=TRUE)
# Multiple Linear Model with higher terms of interest
df2<-higher_terms(df1,4)
model_squared <- transformed(model_transformed,output_transformed,df2,3)
output_squared <- analysis(df3,model_squared,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=TRUE)
# Transformed Multiple Linear Model with higher terms
model_squared_transformed <- transformed(model_squared,output_squared,df3,4)
output<-analysis(df4,model_squared_transformed,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=FALSE)
# Lasso
lasso <- lasso_model(df3)
# Ridge Regression
ridge <- ridge_regression_model(df3)
# Plot of the models assessment
plot_comparison()
# Necessaries libraries to explore the data
load.libraries <- c('data.table', 'testthat', 'gridExtra', 'corrplot', 'GGally', 'ggplot2', 'e1071', 'dplyr','leaps','car','MASS','gtools','DAAG','glmnet')
install.lib <- load.libraries[!load.libraries %in% installed.packages()]
for(libs in install.lib) install.packages(libs, dependences = TRUE)
sapply(load.libraries, require, character = TRUE)
# include DAAG
# Function sources
source('~/Desktop/factoring.R')
source('~/Desktop/analysis.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Descriptive and Comparative Analysis/analysis.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/fitting.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Transformations/transformed_fitting.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/quadratic.R')
source('~/Desktop/quadratic_transform.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/remove_neighborhood.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Descriptive and Comparative Analysis/plot_comparison.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Shrinkage Methods/ridge_regression.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Shrinkage Methods/lasso.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Higher Terms/higher_terms.R')
# Importation of training and test set
train <- fread("/Users/louisdevitry/Documents/Education/KTH/Bachelor thesis/Data/train.csv" ,stringsAsFactors=FALSE)
test <- fread("/Users/louisdevitry/Documents/Education/KTH/Bachelor thesis/Data/test.csv" ,stringsAsFactors=FALSE)
# Choose neighborhoods of interest
neigh<-FALSE
if(neigh){train<-removing_neighborhoods(train)}
# Linear Model
# Multiple Linear Model
model<-fitting(train)
output<-analysis(df,model,residuals=TRUE,boxcox=TRUE,multicollinearity=TRUE,outliers=TRUE)
# Transformed Multiple Linear Model
model_transformed <- transformed(model,output,df,1)
output_transformed<-analysis(df1,model_transformed,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=TRUE)
# Multiple Linear Model with higher terms of interest
df2<-higher_terms(df1,4)
model_squared <- transformed(model_transformed,output_transformed,df2,3)
output_squared <- analysis(df3,model_squared,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=TRUE)
# Transformed Multiple Linear Model with higher terms
model_squared_transformed <- transformed(model_squared,output_squared,df3,4)
output<-analysis(df4,model_squared_transformed,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=FALSE)
# Lasso
lasso <- lasso_model(df3)
# Ridge Regression
ridge <- ridge_regression_model(df3)
# Plot of the models assessment
plot_comparison()
# Necessaries libraries to explore the data
load.libraries <- c('data.table', 'testthat', 'gridExtra', 'corrplot', 'GGally', 'ggplot2', 'e1071', 'dplyr','leaps','car','MASS','gtools','DAAG','glmnet')
install.lib <- load.libraries[!load.libraries %in% installed.packages()]
for(libs in install.lib) install.packages(libs, dependences = TRUE)
sapply(load.libraries, require, character = TRUE)
# include DAAG
# Function sources
source('~/Desktop/factoring.R')
source('~/Desktop/analysis.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Descriptive and Comparative Analysis/analysis.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/fitting.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Transformations/transformed_fitting.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/quadratic.R')
source('~/Desktop/quadratic_transform.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/remove_neighborhood.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Descriptive and Comparative Analysis/plot_comparison.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Shrinkage Methods/ridge_regression.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Shrinkage Methods/lasso.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Higher Terms/higher_terms.R')
# Importation of training and test set
train <- fread("/Users/louisdevitry/Documents/Education/KTH/Bachelor thesis/Data/train.csv" ,stringsAsFactors=FALSE)
test <- fread("/Users/louisdevitry/Documents/Education/KTH/Bachelor thesis/Data/test.csv" ,stringsAsFactors=FALSE)
# Choose neighborhoods of interest
neigh<-FALSE
if(neigh){train<-removing_neighborhoods(train)}
# Linear Model
# Multiple Linear Model
model<-fitting(train)
output<-analysis(df,model,residuals=TRUE,boxcox=TRUE,multicollinearity=TRUE,outliers=TRUE)
# Transformed Multiple Linear Model
model_transformed <- transformed(model,output,df,1)
output_transformed<-analysis(df1,model_transformed,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=TRUE)
# Multiple Linear Model with higher terms of interest
df2<-higher_terms(df1,4)
model_squared <- transformed(model_transformed,output_transformed,df2,3)
output_squared <- analysis(df3,model_squared,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=TRUE)
# Transformed Multiple Linear Model with higher terms
model_squared_transformed <- transformed(model_squared,output_squared,df3,4)
output<-analysis(df4,model_squared_transformed,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=FALSE)
# Lasso
lasso <- lasso_model(df3)
# Ridge Regression
ridge <- ridge_regression_model(df3)
# Plot of the models assessment
plot_comparison()
install.packages("SparseLearner")
library("SparseLearner", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
View(df3)
View(df4)
Bagging.fit <- Bagging.lasso(x=as.matrix(df4[, -34]), y=as.matrix(df4[, 34]),
family=c("gaussian"), M=100, predictor.subset=round((9/10)*ncol(x)),
predictor.importance=TRUE, trimmed=FALSE, weighted=TRUE, seed=0123)
x<-as.matrix(df4[, -34])
Bagging.fit <- Bagging.lasso(x=x, y=as.matrix(df4[, 34]),
family=c("gaussian"), M=100, predictor.subset=round((9/10)*ncol(x)),
predictor.importance=TRUE, trimmed=FALSE, weighted=TRUE, seed=0123)
x<-as.matrix(df4[, -34])
Bagging.fit <- Bagging.lasso(x=x, y=as.matrix(df4[, 34]),
family=c("gaussian"), M=10, predictor.subset=round((9/10)*ncol(x)),
predictor.importance=TRUE, trimmed=FALSE, weighted=TRUE, seed=0123)
# Print a 'bagging' object fitted by the Bagging.fit function.
Print.bagging(Bagging.fit)
# Fix some NAs
test$GarageYrBlt[is.na(test$GarageYrBlt)] <- mean(train$GarageYrBlt[!is.na(train$GarageYrBlt)])
test$MasVnrArea[is.na(test$MasVnrArea)] <- mean(train$MasVnrArea[!is.na(train$MasVnrArea)])
test$LotFrontage[is.na(test$LotFrontage)] <- mean(train$LotFrontage[!is.na(train$LotFrontage)])
# Factoring categorical predictors
new_names <<- c('paved','regshape','alley_pave','flat','gentle_slope','cul_de_sac_fr3'
,'nbhd_price_level','prox1','prox2','dwelling','house_style_price_level','roof_style'
,'roof_matl','ext1_price_level','ext2_price_level','masonry_type'
,'exterior_qual_level','exterior_cond_level','foundation_level'
,'basement_qual_level','basement_cond_level','basement_exposure_level'
,'basementfin_type1_level','basementfin_type2_level','heating_level'
,'heating_qc_level','central_air_yes','electrical_level','kitchen_qual_level'
,'functionality_level','fireplace_qual_level','garage_type_level'
,'garage_finish_level','garage_qual_level','garage_cond_level'
,'paved_driveway_level','pool_qc_level','fence_qual_level','sale_type_level'
,'sale_condition_level','zoning_level')
# Original names of the categorical predictors
old_names <<- c('Street','LotShape','Alley','LandContour','LandSlope','LotConfig'
,'Neighborhood','Condition1','Condition2','BldgType','HouseStyle'
,'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType'
,'ExterQual','ExterCond','Foundation','BsmtQual','BsmtCond'
,'BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC'
,'CentralAir','Electrical','KitchenQual','Functional','FireplaceQu'
,'GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive'
,'PoolQC','Fence','SaleType','SaleCondition','MSZoning')
# Future list of the mean price per level for each predictor
price_summary <- list()
# Factoring the data accoding to the aforementioned list
for (i in 1:length(old_names))
{
# Construction of the list
price_summary[[i]]<-summarize(group_by(train, train[[old_names[i]]]),mean(SalePrice, na.rm=T))
matrix<-as.matrix(price_summary[[i]])
# Handling NA levels
# Temporary variable to control NA values
temp<-0
# Factor NA level if any
if(is.na(matrix[dim(matrix)[1],1]))
{
temp<-1
test[[new_names[i]]][is.na(test[[old_names[i]]])]<-matrix[dim(matrix)[1],2]
}
# Factor non NA levels
for (j in 1:(dim(matrix)[1]-temp))
{
test[[new_names[i]]][test[[old_names[i]]]==matrix[j,1]]<-matrix[j,2]
}
# Convert factors into numeric ones
test[[new_names[i]]]<-as.numeric(test[[new_names[i]]])
}
# Deleting factored/unwanted predictors
test$Id <- NULL
test$GrLivArea <- NULL
test$TotalBsmtSF <- NULL
test$Utilities<-NULL
test$MiscFeature <- NULL
test$MiscVal <- NULL
assign("seqq",which(colnames(test) %in% old_names))
# Linear model preparation
# Removing duplicate/unwanted columns
df_test <- test
df_test <- subset(df_test, select = -seqq )
df_test[["1stFlrSF 2"]] <- df_test[["1stFlrSF"]]^2
df_test[["OpenPorchSF 4"]] <- df_test[["OpenPorchSF"]]^4
df_test[["GarageYrBlt 4"]] <- df_test[["GarageYrBlt"]]^4
df_test[["BsmtFullBath 3"]] <- df_test[["BsmtFullBath"]]^3
df_test[is.na(df_test)] <- 0
pred <- Predict.bagging(Bagging.fit, newx=as.matrix(df_test), y=NULL, trimmed=FALSE)
exp(pred$y.new)
submission<-data.frame(exp(pred$y.new))
View(submission)
write.csv(submission,file = "submission.csv")
x<-as.matrix(df4[, -34])
Bagging.fit <- Bagging.lasso(x=x, y=as.matrix(df4[, 34]),
family=c("gaussian"), M=50, predictor.subset=round((9/10)*ncol(x)),
predictor.importance=TRUE, trimmed=FALSE, weighted=TRUE, seed=0123)
# Print a 'bagging' object fitted by the Bagging.fit function.
Print.bagging(Bagging.fit)
# Make predictions from a bagging LASSO linear regression model.
pred <- Predict.bagging(Bagging.fit, newx=as.matrix(df_test), y=NULL, trimmed=FALSE)
val<-exp(pred$y.new)
x<-as.matrix(df4[, -34])
Bagging.fit <- Bagging.lasso(x=x, y=as.matrix(df4[, 34]),
family=c("gaussian"), M=100, predictor.subset=round((9/10)*ncol(x)),
predictor.importance=TRUE, trimmed=FALSE, weighted=TRUE, seed=0123)
# Print a 'bagging' object fitted by the Bagging.fit function.
Print.bagging(Bagging.fit)
# Make predictions from a bagging LASSO linear regression model.
pred <- Predict.bagging(Bagging.fit, newx=as.matrix(df_test), y=NULL, trimmed=FALSE)
val<-exp(pred$y.new)
x<-as.matrix(df4[, -34])
Bagging.fit <- Bagging.lasso(x=x, y=as.matrix(df4[, 34]),
family=c("gaussian"), M=100, predictor.subset=round((9/10)*ncol(x)),
predictor.importance=TRUE, trimmed=TRUE, weighted=TRUE, seed=0123)
# Print a 'bagging' object fitted by the Bagging.fit function.
Print.bagging(Bagging.fit)
# Make predictions from a bagging LASSO linear regression model.
pred <- Predict.bagging(Bagging.fit, newx=as.matrix(df_test), y=NULL, trimmed=FALSE)
val<-exp(pred$y.new)
submission<-data.frame(val)
write.csv(submission,file = "submission.csv")
source('/Applications/bagging.R')
View(df4)
x<-as.matrix(df4[, -34])
Bagging.fit <- Bagging.lasso(x=x, y=as.matrix(df4[, 34]),
family=c("gaussian"), M=20, predictor.subset=round((9/10)*ncol(x)),
predictor.importance=FALSE, trimmed=TRUE, weighted=TRUE, seed=0123)
# Print a 'bagging' object fitted by the Bagging.fit function.
Print.bagging(Bagging.fit)
# Make predictions from a bagging LASSO linear regression model.
pred <- Predict.bagging(Bagging.fit, newx=as.matrix(df_test), y=NULL, trimmed=FALSE)
val<-exp(pred$y.new)
library("SparseLearner", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
x<-as.matrix(df4[, -34])
Bagging.fit <- Bagging.lasso(x=x, y=as.matrix(df4[, 34]),
family=c("gaussian"), M=20, predictor.subset=round((9/10)*ncol(x)),
predictor.importance=FALSE, trimmed=TRUE, weighted=TRUE, seed=0123)
# Print a 'bagging' object fitted by the Bagging.fit function.
Print.bagging(Bagging.fit)
# Make predictions from a bagging LASSO linear regression model.
pred <- Predict.bagging(Bagging.fit, newx=as.matrix(df_test), y=NULL, trimmed=FALSE)
val<-exp(pred$y.new)
x<-as.matrix(df4[, -34])
Bagging.fit <- Bagging.lasso(x=x, y=as.matrix(df4[, 34]),
family=c("gaussian"), M=20, predictor.subset=round((9/10)*ncol(x)),
predictor.importance=FALSE, trimmed=FALSE, weighted=TRUE, seed=0123)
# Print a 'bagging' object fitted by the Bagging.fit function.
Print.bagging(Bagging.fit)
# Make predictions from a bagging LASSO linear regression model.
pred <- Predict.bagging(Bagging.fit, newx=as.matrix(df_test), y=NULL, trimmed=FALSE)
val<-exp(pred$y.new)
vif(model_squared_transformed)
library("car", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
vif(model_squared_transformed)
x<-as.matrix(df1[, -34])
Bagging.fit <- Bagging.lasso(x=x, y=as.matrix(df1[, 34]),
family=c("gaussian"), M=20, predictor.subset=round((9/10)*ncol(x)),
predictor.importance=FALSE, trimmed=FALSE, weighted=TRUE, seed=0123)
# Print a 'bagging' object fitted by the Bagging.fit function.
Print.bagging(Bagging.fit)
# Make predictions from a bagging LASSO linear regression model.
pred <- Predict.bagging(Bagging.fit, newx=as.matrix(df_test), y=NULL, trimmed=FALSE)
val<-exp(pred$y.new)
x<-as.matrix(df1[, -34])
Bagging.fit <- Bagging.lasso(x=x, y=as.matrix(df1[, 34]),
family=c("gaussian"), M=20, predictor.subset=round((9/10)*ncol(x)),
predictor.importance=TRUE, trimmed=FALSE, weighted=TRUE, seed=0123)
# Print a 'bagging' object fitted by the Bagging.fit function.
Print.bagging(Bagging.fit)
# Make predictions from a bagging LASSO linear regression model.
pred <- Predict.bagging(Bagging.fit, newx=as.matrix(df_test), y=NULL, trimmed=FALSE)
val<-exp(pred$y.new)
# Necessaries libraries to explore the data
load.libraries <- c('data.table', 'testthat', 'gridExtra', 'corrplot', 'GGally', 'ggplot2', 'e1071', 'dplyr','leaps','car','MASS','gtools','DAAG','glmnet')
install.lib <- load.libraries[!load.libraries %in% installed.packages()]
for(libs in install.lib) install.packages(libs, dependences = TRUE)
sapply(load.libraries, require, character = TRUE)
# include DAAG
# Function sources
source('~/Desktop/factoring.R')
source('~/Desktop/analysis.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Descriptive and Comparative Analysis/analysis.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/fitting.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Transformations/transformed_fitting.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/quadratic.R')
source('~/Desktop/quadratic_transform.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/remove_neighborhood.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Descriptive and Comparative Analysis/plot_comparison.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Shrinkage Methods/ridge_regression.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Shrinkage Methods/lasso.R')
source('~/Documents/Education/KTH/Bachelor thesis/Bachelor Thesis/Higher Terms/higher_terms.R')
# Importation of training and test set
train <- fread("/Users/louisdevitry/Documents/Education/KTH/Bachelor thesis/Data/train.csv" ,stringsAsFactors=FALSE)
test <- fread("/Users/louisdevitry/Documents/Education/KTH/Bachelor thesis/Data/test.csv" ,stringsAsFactors=FALSE)
# Choose neighborhoods of interest
neigh<-FALSE
if(neigh){train<-removing_neighborhoods(train)}
# Linear Model
# Multiple Linear Model
model<-fitting(train)
output<-analysis(df,model,residuals=TRUE,boxcox=TRUE,multicollinearity=TRUE,outliers=TRUE)
# Transformed Multiple Linear Model
model_transformed <- transformed(model,output,df,1)
output_transformed<-analysis(df1,model_transformed,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=TRUE)
# Multiple Linear Model with higher terms of interest
df2<-higher_terms(df1,4)
model_squared <- transformed(model_transformed,output_transformed,df2,3)
output_squared <- analysis(df3,model_squared,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=TRUE)
# Transformed Multiple Linear Model with higher terms
model_squared_transformed <- transformed(model_squared,output_squared,df3,4)
output<-analysis(df4,model_squared_transformed,residuals=TRUE,boxcox=FALSE,multicollinearity=TRUE,outliers=FALSE)
# Lasso
lasso <- lasso_model(df3)
# Ridge Regression
ridge <- ridge_regression_model(df3)
# Plot of the models assessment
plot_comparison()
